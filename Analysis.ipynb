{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f52711",
   "metadata": {},
   "source": [
    "# Building Chat with Embeddings of Pdfs, User Profile and Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705f86d",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9b5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.chains import LLMChain, LLMMathChain, TransformChain, SequentialChain\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.llms import GooglePalm\n",
    "import google.generativeai as palm\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
    "                                               chunk_overlap=20,\n",
    "                                               length_function=len)\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory, \n",
    "                                                  ConversationSummaryMemory, \n",
    "                                                  ConversationBufferWindowMemory,\n",
    "                                                  ConversationKGMemory)\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms import GooglePalm\n",
    "from fastapi import FastAPI, HTTPException, Request\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "\n",
    "palm.configure(api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c9cc0",
   "metadata": {},
   "source": [
    "## Tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2109807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        json_string = json_file.read()\n",
    "    return json_string\n",
    "\n",
    "\n",
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        json_string = json_file.read()\n",
    "    return json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf410a65",
   "metadata": {},
   "source": [
    "## Main code flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629372a",
   "metadata": {},
   "source": [
    "### Using Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ec2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(\n",
    "    model='models/chat-bison-001',\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=80000,\n",
    "    google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM'\n",
    ")\n",
    "\n",
    "\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d007e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_json_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_json_file\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUST_PROFILE.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m initial_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mAct like a expert diet chatbot use given formulas and user data to continue the chat:\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I assist you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124mUserData : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     42\u001b[0m initial_message \u001b[38;5;241m=\u001b[39m conversation_buf(initial_message)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_json_file' is not defined"
     ]
    }
   ],
   "source": [
    "user_data = load_json_file('CUST_PROFILE.json')\n",
    "\n",
    "initial_message = f'''Act like a expert diet chatbot use given formulas and user data to continue the chat:\n",
    "\n",
    "\"Bot\" : \"How can I assist you?\"\n",
    "\"User\" : \"Can you calculate my macros?\"\n",
    "\"Bot\" : \"What is your weight\"\n",
    "\n",
    "Calculations :\n",
    "\n",
    "### Recommended Calories Calculations:\n",
    "\n",
    "**Step 1: BMR Calculation**\n",
    "- For Men:\n",
    "  - BMR = (10 × weight in kg) + (6.25 × height in cm) - (5 × age in years) + 5\n",
    "- For Women:\n",
    "  - BMR = (10 × weight in kg) + (6.25 × height in cm) - (5 × age in years) - 161\n",
    "\n",
    "**Step 2: Calculate Calories Needed Based on Activity Level**\n",
    "- Sedentary (No Exercise):\n",
    "  - Multiplier: 1.2\n",
    "- Lightly Active (Walking, Yoga, etc):\n",
    "  - Multiplier: 1.375\n",
    "- Moderately Active (Training around 3 times a week):\n",
    "  - Multiplier: 1.55\n",
    "- Super Active (Training more than 3 times a week):\n",
    "  - Multiplier: 1.7\n",
    "\n",
    "In cases where customer input is not available (e.g., Healthians), a default multiplier of 1.375 is recommended.\n",
    "\n",
    "**Step 3: Adjust Calories for Specific Goals**\n",
    "- Weight Loss: Reduce by 500 calories\n",
    "- Weight Maintenance: Reduce by 200 calories\n",
    "- Muscle Building: No reduction (0 calories)\n",
    "\n",
    "In cases where specific goals are not provided, such as in the tie-up with Healthians, the following logic is used:\n",
    "- If BMI is less than 23, reduce by 200 calories\n",
    "- If BMI is more than 23, reduce by 500 calories\n",
    "\n",
    "UserData : {user_data}'''\n",
    "\n",
    "initial_message = conversation_buf(initial_message)\n",
    "initial_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273ce9b",
   "metadata": {},
   "source": [
    "#### Run the Below for Simple Macros calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd7e51cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the message: HI\n",
      "Spent a total of 0 tokens\n",
      "Hello, how can I help you?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     Query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the message: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m count_tokens(conversation_buf, Query)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    Query = input(\"Enter the message: \")\n",
    "    response = count_tokens(conversation_buf, Query)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606d823",
   "metadata": {},
   "source": [
    "## Embedding Documents to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c564c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import GooglePalmEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2271d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64799e2b",
   "metadata": {},
   "source": [
    "### Multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb55e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_chunks_from_pdfs(pdf_names, chunk_size=1000, chunk_overlap=200):\n",
    "    all_chunks = []\n",
    "\n",
    "    for pdf_name in pdf_names:\n",
    "        pdf_reader = PdfReader(pdf_name)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.split_text(text=text)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "# List of PDF file names you want to process\n",
    "pdf_names = ['ICMR_GuidelinesType2diabetes2018_0.pdf', 'DietaryGuidelinesforNINwebsite.pdf' , \n",
    "            \"kupdf.net_1000-indian-recipes.pdf\" , \"Recommended calories Calculation.pdf\", \"JsonConPdf.pdf\"]\n",
    "\n",
    "# Extract chunks from the PDFs\n",
    "chunks = extract_chunks_from_pdfs(pdf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76514901",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_name = \"embeddings\"\n",
    "embeddings = GooglePalmEmbeddings(google_api_key=\"AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM\")\n",
    "VectorStore = FAISS.from_texts(chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e6cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorStore.as_retriever(search_kwargs = {\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7c6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "\n",
      "\n",
      "\n",
      "Here is the final Response: \n",
      "The document is about guidelines for management of type 2 diabetes.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the document about?\" # Enter the query here\n",
    "docs = VectorStore.similarity_search(query=query, k=3)\n",
    "\n",
    "llm = GooglePalm(\n",
    "    model='models/chat-bison-001',\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=,\n",
    "    google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM'\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
    "with get_openai_callback() as cb:\n",
    "    response = chain.run(input_documents=docs, question=query)\n",
    "    print(cb)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Here is the final Response: \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ede48",
   "metadata": {},
   "source": [
    "### Recursive Chat with the Document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805f755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: What is the document about?\n",
      "Bot Response: \n",
      "The document is about guidelines for management of type 2 diabetes.\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: ok can you calculate my macros?\n",
      "Bot Response: \n",
      "Your macros are 100g protein, 50g fat, and 250g carbs.\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: what is my name?\n",
      "Bot Response: \n",
      "575855514c514a\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: what is my profile name?\n",
      "Bot Response: \n",
      "sarthakmanchanda1011@gmail.com\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: can you suggest be the best diet for the day?\n",
      "Bot Response: \n",
      "The best diet for the day is a diet that is rich in fiber, proteins, and fats. It should also be low in carbohydrates. Some good choices for breakfast include oatmeal, yogurt, or eggs. For lunch, you could have a salad with grilled chicken or fish. For dinner, you could have a vegetable stir-fry or a grilled fish fillet.\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: give it in properly structured format?\n",
      "Bot Response: \n",
      "6.2.1 Dietary Recommendations:\n",
      "(i) Energy:\n",
      "Sufficient to attain or maintain a reasonable body weight for adults, normal growth \n",
      "and development for children and adolescents, to meet the increased needs during \n",
      "pregnancy and lactation and recovery from illness. Daily physical activity and exercise \n",
      "needs to be considered.\n",
      "Ideal Body Weight (IBW) = (Height in cm – 100) * 0.9.\n",
      "Approximately, 25 kcals/kg ideal body weight/day can be given to a moderately \n",
      "active patient with diabetes. The change in the daily calorie should be a gradual \n",
      "process, and not more than 500 calories/day.\n",
      "(ii) Energy or Calorie Distribution:\n",
      "(a) Carbohydrates: \n",
      "Evidence is inconclusive for an ideal amount of carbohydrate intake for people \n",
      "with diabetes. Therefore, collaborative goals should be developed for individuals \n",
      "\n",
      "\n",
      "\n",
      "Enter your query: what was my previous query?\n",
      "Bot Response: \n",
      "The previous query was about the vibration perception threshold (VPT) test.\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: no no?\n",
      "Bot Response: \n",
      "no\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: can you give summary of my profile/\n",
      "Bot Response: \n",
      "The user's profile is as follows:\n",
      "- Name: Sarthak\n",
      "- Email: sarthakmanchanda1011@gmail.com\n",
      "- Gender: Male\n",
      "- Age: 15 to 18 years\n",
      "- Height: 68 inches\n",
      "- Diet plan type: Weight loss\n",
      "- Subcategory: Weight loss\n",
      "- Plan type: Freemium\n",
      "- Trial duration: 0 days\n",
      "- Free plan expiry date: 22-Jul-2023 22:02:38\n",
      "- Created date: 22-Jul-2023 21:20:00\n",
      "- Updated date: 22-Jul-2023 21:20:25\n",
      "\n",
      "\n",
      "\n",
      "Enter your query: using this can you calulate my carbs for day?\n",
      "Bot Response: \n",
      "The recommended daily intake of carbohydrates is 55-60% of total calories. For a person who consumes 2000 calories per day, the recommended daily intake of carbohydrates is 1100-1200 calories. This translates to 225-250 grams of carbohydrates per day.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m query \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter your query: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m      5\u001b[0m         docs \u001b[38;5;241m=\u001b[39m VectorStore\u001b[38;5;241m.\u001b[39msimilarity_search(query\u001b[38;5;241m=\u001b[39mquery, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel/kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "query = \"\"\n",
    "while query != 'Q':\n",
    "    query = input(\"Enter your query: \")\n",
    "    with get_openai_callback() as cb:\n",
    "        docs = VectorStore.similarity_search(query=query, k=3)\n",
    "        response = chain.run(input_documents=docs, question=query)\n",
    "        print(\"Bot Response: \")\n",
    "        print(response)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Chat Ended!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa10dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82becc1b",
   "metadata": {},
   "source": [
    "### Research on Vector Databases for embeddings:\n",
    "1. Chroma\n",
    "2. Haystack by DeepsetAI\n",
    "3. Faiss by Facebook\n",
    "4. Milvus\n",
    "5. pgvector\n",
    "6. Pinecone\n",
    "7. Supabase\n",
    "8. Qdrant\n",
    "9. Vespa\n",
    "10. Weaviate\n",
    "11. DeepLake\n",
    "12. VectorStore from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0af43",
   "metadata": {},
   "source": [
    "## Adding Conversational Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c3551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buf = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d151823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = f'''Act like a expert diet chatbot use given formulas and user data to continue the chat:\n",
    "\n",
    "Calculations :\n",
    "\n",
    "### Recommended Calories Calculations:\n",
    "\n",
    "**Step 1: BMR Calculation**\n",
    "- For Men:\n",
    "  - BMR = (10 × weight in kg) + (6.25 × height in cm) - (5 × age in years) + 5\n",
    "- For Women:\n",
    "  - BMR = (10 × weight in kg) + (6.25 × height in cm) - (5 × age in years) - 161\n",
    "\n",
    "**Step 2: Calculate Calories Needed Based on Activity Level**\n",
    "- Sedentary (No Exercise):\n",
    "  - Multiplier: 1.2\n",
    "- Lightly Active (Walking, Yoga, etc):\n",
    "  - Multiplier: 1.375\n",
    "- Moderately Active (Training around 3 times a week):\n",
    "  - Multiplier: 1.55\n",
    "- Super Active (Training more than 3 times a week):\n",
    "  - Multiplier: 1.7\n",
    "\n",
    "In cases where customer input is not available (e.g., Healthians), a default multiplier of 1.375 is recommended.\n",
    "\n",
    "**Step 3: Adjust Calories for Specific Goals**\n",
    "- Weight Loss: Reduce by 500 calories\n",
    "- Weight Maintenance: Reduce by 200 calories\n",
    "- Muscle Building: No reduction (0 calories)\n",
    "\n",
    "In cases where specific goals are not provided, such as in the tie-up with Healthians, the following logic is used:\n",
    "- If BMI is less than 23, reduce by 200 calories\n",
    "- If BMI is more than 23, reduce by 500 calories\n",
    "\n",
    "UserData : {user_data}'''\n",
    "\n",
    "# initial_message = conversation_buf(initial_message , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17de0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConversationalRetrievalChain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0be7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(llm, \n",
    "                                              retriever=\n",
    "                                              VectorStore.as_retriever(search_kwargs={'k' : 1}),\n",
    "                                              return_source_documents=True, rephrase_question=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722cb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "# result = chain({\"question\": initial_message, 'chat_history':chat_history}, return_only_outputs=True)\n",
    "while query != 'Q':\n",
    "    query = input(\"Enter the Query: \")\n",
    "    result = chain({\"question\": query, 'chat_history':chat_history}, return_only_outputs=True)\n",
    "    chat_history += [(query, result[\"answer\"])]\n",
    "    print(result['answer'])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3abf8ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the Harris-Benedict equation, your BMR is 1744 calories. Your activity level is moderately active, so your total daily calorie needs are 1744 * 1.55 = 2712 calories. To lose weight, you need to reduce your calorie intake by 500 calories, so your daily calorie intake should be 2712 - 500 = 2212 calories.\\n\\nHere is a sample meal plan for you:\\n\\n* Breakfast: Oatmeal with fruit and nuts (300 calories)\\n* Lunch: Salad with grilled chicken or tofu (400 calories)\\n* Dinner: Salmon with roasted vegetables (400 calories)\\n* Snacks: Yogurt with fruit (100 calories) and apple (100 calories)\\n\\nThis meal plan provides you with 2212 calories, which is the amount you need to eat to lose weight. It is also balanced and nutritious, providing you with plenty of protein, carbohydrates, and fiber.\\n\\nI hope this helps!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query: can you calculate my carbs?\n",
      "I don't know.\n",
      "\n",
      "\n",
      "\n",
      "Enter the query: I am getting headache?\n",
      "no\n",
      "\n",
      "\n",
      "\n",
      "Enter the query: can get diet plan?\n",
      "Yes, there is a sample meal plan for adult man (sedentary) and adult woman (sedentary) in the annexures.\n",
      "\n",
      "\n",
      "\n",
      "Enter the query: ok, give me proper stable diet?\n",
      "Eat variety of foods to ensure a balanced diet.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"\"\n",
    "while query != 'Q':\n",
    "    query = input(\"Enter the query: \")\n",
    "    result = chain({\"question\": query, 'chat_history': chat_history}, return_only_outputs=True)\n",
    "    print(result[\"answer\"])\n",
    "    print(\"\\n\\n\")\n",
    "    chat_history += [(query, result[\"answer\"])]\n",
    "print(\"Chat Ended!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4f6bf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Query: hi\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A single string input was passed in, but this chain expects multiple inputs ({'chat_history', 'question'}). When a chain expects multiple inputs, please call it by passing in a dictionary, eg `chain({'foo': 1, 'bar': 2})`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the Query: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/n/n\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain/chains/base.py:268\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m     inputs: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     include_run_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    242\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m            `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    270\u001b[0m         callbacks,\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m     new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain/chains/base.py:415\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         _input_keys \u001b[38;5;241m=\u001b[39m _input_keys\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory_variables)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_input_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single string input was passed in, but this chain expects \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple inputs (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_input_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). When a chain expects \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple inputs, please call it by passing in a dictionary, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meg `chain(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfoo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: 1, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: 2})`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m         )\n\u001b[1;32m    421\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mlist\u001b[39m(_input_keys)[\u001b[38;5;241m0\u001b[39m]: inputs}\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: A single string input was passed in, but this chain expects multiple inputs ({'chat_history', 'question'}). When a chain expects multiple inputs, please call it by passing in a dictionary, eg `chain({'foo': 1, 'bar': 2})`"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"Enter the Query: \")\n",
    "    result = chain(query, )\n",
    "    print(result)\n",
    "    print(\"/n/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea12837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
