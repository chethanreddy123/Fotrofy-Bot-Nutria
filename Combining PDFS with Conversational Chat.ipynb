{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462c03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
    "                                               chunk_overlap=20,\n",
    "                                               length_function=len)\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76b2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(\n",
    "    model='models/chat-bison-001',\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024,\n",
    "    google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f480321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_chunks_from_pdfs(pdf_names, chunk_size=1000, chunk_overlap=200):\n",
    "    all_chunks = []\n",
    "\n",
    "    for pdf_name in pdf_names:\n",
    "        pdf_reader = PdfReader(pdf_name)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.split_text(text=text)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "# List of PDF file names you want to process\n",
    "pdf_names = ['ICMR_GuidelinesType2diabetes2018_0.pdf', 'DietaryGuidelinesforNINwebsite.pdf' , \n",
    "            \"kupdf.net_1000-indian-recipes.pdf\" , \"Recommended calories Calculation.pdf\"]\n",
    "\n",
    "# Extract chunks from the PDFs\n",
    "chunks = extract_chunks_from_pdfs(pdf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a671aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_name = \"embeddings\"\n",
    "embeddings = GooglePalmEmbeddings(google_api_key=\"AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM\")\n",
    "VectorStore = FAISS.from_texts(chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47055bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the document?\"\n",
    "docs = VectorStore.similarity_search(query=query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a582c507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationalRetrievalChain\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract method _get_relevant_documents (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain/chains/conversational_retrieval/base.py:356\u001b[0m, in \u001b[0;36mConversationalRetrievalChain.from_llm\u001b[0;34m(cls, llm, retriever, condense_question_prompt, chain_type, verbose, condense_question_llm, combine_docs_chain_kwargs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m _llm \u001b[38;5;241m=\u001b[39m condense_question_llm \u001b[38;5;129;01mor\u001b[39;00m llm\n\u001b[1;32m    350\u001b[0m condense_question_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m    351\u001b[0m     llm\u001b[38;5;241m=\u001b[39m_llm,\n\u001b[1;32m    352\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mcondense_question_prompt,\n\u001b[1;32m    353\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    354\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    355\u001b[0m )\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_docs_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondense_question_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain/load/serializable.py:75\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ConversationalRetrievalChain\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract method _get_relevant_documents (type=type_error)"
     ]
    }
   ],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(llm, \n",
    "                               retriever=docs,\n",
    "                               return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee97973",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain({\"question\": query, 'chat_history': chat_history}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
